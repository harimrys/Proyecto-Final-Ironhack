{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Anaconda\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from pinecone import Pinecone\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "my_key = os.getenv(\"my_key\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este código tiene como objetivo cargar un conjunto de datos, generar vectores de embeddings a partir del contenido de los libros, y luego subir estos vectores a Pinecone para hacer búsquedas semánticas más adelante. A continuación, se explica cada parte del código:\n",
    "\n",
    "1. **Cargar el DataFrame**:\n",
    "   - Se utiliza `pandas` para leer un archivo CSV que contiene información de libros, incluyendo su título, descripción y otros datos. Este archivo se almacena en el DataFrame `df`.\n",
    "\n",
    "2. **Crear una instancia de Pinecone**:\n",
    "   - Aquí se inicializa Pinecone utilizando una clave de API (`my_key`), lo que permite conectarse al servicio de Pinecone.\n",
    "   - Luego, se accede a un índice en Pinecone llamado `'books'`, donde se almacenarán los vectores generados para cada libro.\n",
    "\n",
    "3. **Cargar el modelo de embeddings**:\n",
    "   - Se utiliza el modelo de **SentenceTransformer** llamado `'all-MiniLM-L6-v2'`, que es un modelo ligero diseñado para convertir textos en vectores numéricos (embeddings). Estos vectores permiten hacer búsquedas semánticas comparando los significados de las descripciones de los libros.\n",
    "\n",
    "4. **Generar y subir los vectores a Pinecone**:\n",
    "   - Para cada libro en el DataFrame, el código toma el campo `content` (que es una combinación del título y la descripción del libro) y genera un vector de embeddings con el modelo.\n",
    "   - Luego, este vector se sube a Pinecone utilizando la función `upsert()`, que asocia el vector generado con un ID correspondiente al libro (en este caso, el índice del DataFrame).\n",
    "\n",
    "5. **Resultado final**:\n",
    "   - Una vez que se procesan todos los libros, los vectores están cargados en Pinecone, lo que permite que la aplicación pueda realizar búsquedas semánticas eficientemente.\n",
    "\n",
    "Este proceso es clave para hacer recomendaciones de libros basadas en el contenido textual, permitiendo búsquedas más precisas y personalizadas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectores cargados en Pinecone.\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/df_images.csv\")  \n",
    "\n",
    "pc = Pinecone(api_key= my_key)  \n",
    "index = pc.Index('books')\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2') \n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    vector = model.encode(row['content'])  \n",
    "    index.upsert([(str(i), vector.tolist())])  \n",
    "\n",
    "print(\"Vectores cargados en Pinecone.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
